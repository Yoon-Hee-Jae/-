{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1018b897",
      "metadata": {
        "id": "1018b897"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8925397",
      "metadata": {
        "id": "f8925397"
      },
      "source": [
        "<span style = 'font-size:1.2em;line-height:1.5em'><b>1. </b>실습 파일 \"1_Activation_Function_Image_Read.ipynb\"에 있는 numpy 기반의 activation함수들을 Pytorch기반의 코드로 변환하세요. 단, nn.ReLU(), F.relu()와 같이 Pytorch에서 기본으로 제공하는 활성화 함수를 사용하지 말고, 처음부터 짜보세요.</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "568b18b4",
      "metadata": {
        "id": "568b18b4",
        "outputId": "3a43975b-7737-44d0-9248-a5af841d13bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 1]\n",
            "tensor([0, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "예시\n",
        "\"\"\"\n",
        "def step_function_numpy(x):\n",
        "    # x는 numpy array라고 가정\n",
        "    y = x>0\n",
        "    return y.astype(np.int64)\n",
        "\n",
        "def step_function_torch(x):\n",
        "    # x는 torch tensor라고 가정\n",
        "    y = x>0\n",
        "    return y.type(torch.int64)\n",
        "\n",
        "## step_function_test\n",
        "numpy_x = np.array([-1,3,5])\n",
        "torch_x = torch.Tensor(numpy_x)\n",
        "print(step_function_numpy(numpy_x))\n",
        "print(step_function_torch(torch_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb3ef55a",
      "metadata": {
        "id": "bb3ef55a"
      },
      "outputs": [],
      "source": [
        "def sigmoid_numpy(x):\n",
        "    \"\"\"\n",
        "    return sigmoid output\n",
        "    \"\"\"\n",
        "    result = 1/(1+np.exp(-x))\n",
        "    return result\n",
        "\n",
        "def relu_numpy(x):\n",
        "    \"\"\"\n",
        "    return ReLU output\n",
        "    \"\"\"\n",
        "    result = np.maximum(x,0)\n",
        "    return result\n",
        "\n",
        "def softmax1_numpy(x):\n",
        "    exp_sum = np.sum(np.exp(x))\n",
        "    result = np.exp(x)/exp_sum\n",
        "    return result\n",
        "\n",
        "def softmax2_numpy(x):\n",
        "    c=np.max(x)\n",
        "    exp_x = np.exp(x-c) # overflow 대책\n",
        "    exp_sum = np.sum(exp_x)\n",
        "    result = exp_x/exp_sum\n",
        "    return result\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "t3zP3KraGq6w"
      },
      "id": "t3zP3KraGq6w",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e3658d09",
      "metadata": {
        "id": "e3658d09"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "아래 함수들을 작성하세요.\n",
        "\"\"\"\n",
        "def sigmoid_torch(x):\n",
        "    \"\"\"\n",
        "    return sigmoid output\n",
        "    \"\"\"\n",
        "    sigmoid_output = 1 / (1 + torch.exp(-x))\n",
        "    return sigmoid_output\n",
        "\n",
        "\n",
        "def relu_torch(x):\n",
        "    \"\"\"\n",
        "    return ReLU output\n",
        "    \"\"\"\n",
        "    ReLU_output = torch.relu(x)\n",
        "    return ReLU_output\n",
        "\n",
        "def softmax1_torch(x):\n",
        "    \"\"\"\n",
        "    return softmax output\n",
        "    \"\"\"\n",
        "    x = torch.tensor(x)\n",
        "    exp_sum = torch.sum(torch.exp(x))\n",
        "    softmax_output = torch.exp(x) / exp_sum\n",
        "    return softmax_output\n",
        "\n",
        "def softmax2_torch(x):\n",
        "    \"\"\"\n",
        "    return softmax output with the trick\n",
        "    \"\"\"\n",
        "    x = torch.tensor(x)  # NumPy 배열을 PyTorch 텐서로 변환\n",
        "    c = torch.max(x)\n",
        "    exp_x = torch.exp(x - c)  # overflow 대책\n",
        "    exp_sum = torch.sum(exp_x)\n",
        "    softmax_output_with_the_trick = exp_x / exp_sum\n",
        "    return softmax_output_with_the_trick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a37d84e1",
      "metadata": {
        "id": "a37d84e1",
        "outputId": "fdb6385d-5895-48ca-f608-5c410751e84d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9.35762297e-14 9.99954602e-01 9.99999998e-01]\n",
            "[ 0 10 20]\n",
            "[1.92866229e-22 4.53978687e-05 9.99954602e-01]\n",
            "[1.92866229e-22 4.53978687e-05 9.99954602e-01]\n"
          ]
        }
      ],
      "source": [
        "## step_function_test\n",
        "x = np.array([-30,10,20])\n",
        "print(sigmoid_numpy(x))\n",
        "print(relu_numpy(x))\n",
        "print(softmax1_numpy(x))\n",
        "print(softmax2_numpy(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86294d1e",
      "metadata": {
        "id": "86294d1e",
        "outputId": "155b512f-6199-4d40-b3b2-1cffc1cc105a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([9.3576e-14, 9.9995e-01, 1.0000e+00])\n",
            "tensor([ 0., 10., 20.])\n",
            "tensor([1.9287e-22, 4.5398e-05, 9.9995e-01])\n",
            "tensor([1.9287e-22, 4.5398e-05, 9.9995e-01])\n"
          ]
        }
      ],
      "source": [
        "## step_function_test\n",
        "x = torch.Tensor([-30,10,20])\n",
        "print(sigmoid_torch(x))\n",
        "print(relu_torch(x))\n",
        "print(softmax1_torch(x))\n",
        "print(softmax2_torch(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a7f07ee",
      "metadata": {
        "id": "2a7f07ee"
      },
      "source": [
        "<span style = 'font-size:1.2em;line-height:1.5em'><b>2. </b>이제까지 코드는 numpy 형식으로 되어있었습니다. 이를 Pytorch기반의 코드로 바꿔보세요. torch.nn.Linear()나 nn.ReLU()등의 High-level API를 사용하지 마시고, tensor 연산 기반의 코드로 low-level단에서 작성해보세요.</span>\n",
        "\n",
        "- <span style = 'font-size:1.1em;line-height:1.3em'>Hint 1. Activation function들을 Pytorch코드로 변환하셔야 됩니다. (1번문제의 결과물을 활용하셔도 되고, nn.ReLU()와 같은 pytorch에서 제공하는 함수를 사용하셔도 됩니다.)</span>\n",
        "- <span style = 'font-size:1.1em;line-height:1.3em'>Hint 2. network에 있는 numpy array를 Pytorch Tensor 형태로 변환하세요.</span>\n",
        "- <span style = 'font-size:1.1em;line-height:1.3em'>Hint 3. MNIST mini-batch data는 현재 numpy array인데 Pytorch Tensor 형태로 변환하세요.</span>\n",
        "- <span style = 'font-size:1.1em;line-height:1.3em'>Hint 4. Pytorch에서 텐서곱은 torch.matmul()입니다.</span>\n",
        "- <span style = 'font-size:1.1em;line-height:1.3em'>Hint 5. np.argmax()와 torch.argmax()는 같은 역할을 한다.</span>\n",
        "\n",
        "```python\n",
        "a = torch.rand(size=(5,3))\n",
        "print(a)\n",
        "# 결과값\n",
        "#tensor([[0.6298, 0.9776, 0.4705],\n",
        "#        [0.4715, 0.6208, 0.1938],\n",
        "#        [0.5101, 0.3516, 0.7683],\n",
        "#        [0.5044, 0.5985, 0.1055],\n",
        "#        [0.9975, 0.6862, 0.2044]])\n",
        "\n",
        "torch.argmax(a, dim=1)\n",
        "# 결과값\n",
        "# tensor([1, 1, 2, 1, 0])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf5fcc1",
      "metadata": {
        "id": "dbf5fcc1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pickle\n",
        "from mnist import load_mnist\n",
        "from act_func import sigmoid, softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b4f214b",
      "metadata": {
        "id": "6b4f214b"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "338d1395",
      "metadata": {
        "id": "338d1395"
      },
      "outputs": [],
      "source": [
        "def init_network():\n",
        "    fpath = 'sample_weights/sample_weight.pkl'\n",
        "    with open(fpath, 'rb') as f:\n",
        "        network = pickle.load(f)\n",
        "    # network변수안의 모든 key에 대해서 torch.Tensor로 형태 변경\n",
        "    # GPU사용할때를 위해서 해당 tensor를 device로 옮겨놓기\n",
        "\n",
        "    return network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3aea71b",
      "metadata": {
        "id": "c3aea71b"
      },
      "outputs": [],
      "source": [
        "def forward_propagation(network, x):\n",
        "    w1, w2, w3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "    # torch의 행렬곱과 activation function을 활용하여\n",
        "    # forward propagation 나타내기\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada21bca",
      "metadata": {
        "id": "ada21bca",
        "outputId": "68a15f7d-baaa-49eb-e55b-be6fb0d46872"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "미리 학습한 모델의 정확도는 92.52%입니다.\n"
          ]
        }
      ],
      "source": [
        "(x_trn, y_trn), (x_tst, y_tst) = load_mnist(flatten=True, normalize=False)\n",
        "network = init_network(device)\n",
        "\n",
        "## 1. x_trn, y_trn을 device위에 있는 Tensor로 변환하고\n",
        "## 2. forward_propgation을 진행한 결과를 results라는 변수에 저장한 뒤,\n",
        "## 3. torch.argmax()함수를 사용하여 각 행마다 최대 값을 갖는 열의 index를 찾아낸다.\n",
        "## 4. 그리고 위의 결과를 results라는 변수에다 저장한다.\n",
        "\n",
        "\n",
        "print(f'미리 학습한 모델의 정확도는 {100*torch.sum(results==y_trn) / len(y_trn):.2f}%입니다.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}